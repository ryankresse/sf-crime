{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 12.0)\n",
    "matplotlib.rcParams['axes.titlesize'] = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/train.csv.zip', parse_dates=['Dates'])\n",
    "test = pd.read_csv('input/test.csv.zip', parse_dates=['Dates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Category</th>\n",
       "      <th>Descript</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>WARRANTS</td>\n",
       "      <td>WARRANT ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-13 23:33:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>VANNESS AV / GREENWICH ST</td>\n",
       "      <td>-122.424363</td>\n",
       "      <td>37.800414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>GRAND THEFT FROM LOCKED AUTO</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1500 Block of LOMBARD ST</td>\n",
       "      <td>-122.426995</td>\n",
       "      <td>37.800873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>GRAND THEFT FROM LOCKED AUTO</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>PARK</td>\n",
       "      <td>NONE</td>\n",
       "      <td>100 Block of BRODERICK ST</td>\n",
       "      <td>-122.438738</td>\n",
       "      <td>37.771541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Dates        Category                      Descript  \\\n",
       "0 2015-05-13 23:53:00        WARRANTS                WARRANT ARREST   \n",
       "1 2015-05-13 23:53:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
       "2 2015-05-13 23:33:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
       "3 2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
       "4 2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
       "\n",
       "   DayOfWeek PdDistrict      Resolution                    Address  \\\n",
       "0  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
       "1  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
       "2  Wednesday   NORTHERN  ARREST, BOOKED  VANNESS AV / GREENWICH ST   \n",
       "3  Wednesday   NORTHERN            NONE   1500 Block of LOMBARD ST   \n",
       "4  Wednesday       PARK            NONE  100 Block of BRODERICK ST   \n",
       "\n",
       "            X          Y  \n",
       "0 -122.425892  37.774599  \n",
       "1 -122.425892  37.774599  \n",
       "2 -122.424363  37.800414  \n",
       "3 -122.426995  37.800873  \n",
       "4 -122.438738  37.771541  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first see if there are missing values in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dates         0\n",
       "Category      0\n",
       "Descript      0\n",
       "DayOfWeek     0\n",
       "PdDistrict    0\n",
       "Resolution    0\n",
       "Address       0\n",
       "X             0\n",
       "Y             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id            0\n",
       "Dates         0\n",
       "DayOfWeek     0\n",
       "PdDistrict    0\n",
       "Address       0\n",
       "X             0\n",
       "Y             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice. So we have no missing values.\n",
    "\n",
    "\n",
    "Other competitors have had success creating a categorical 'location' variable using latitude and longitude, so we'll do the same.\n",
    "\n",
    "Below, we round lattitude and longitude to two decimal places, then concatenate them into a string we call 'location'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encodeLoc(x):\n",
    "    return  '{}_{}'.format(str(round(x.X,2)), str(round(x.Y, 2)))\n",
    "\n",
    "train['location'] = train.apply(encodeLoc, axis=1)\n",
    "test['location'] = test.apply(encodeLoc, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That took a while, so let's save the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.to_csv('train_with_loc.csv', index=False)\n",
    "test.to_csv('test_with_loc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_with_loc.csv', parse_dates=['Dates'])\n",
    "test = pd.read_csv('test_with_loc.csv', parse_dates=['Dates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Category</th>\n",
       "      <th>Descript</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>WARRANTS</td>\n",
       "      <td>WARRANT ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "      <td>-122.43_37.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "      <td>-122.43_37.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-13 23:33:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>VANNESS AV / GREENWICH ST</td>\n",
       "      <td>-122.424363</td>\n",
       "      <td>37.800414</td>\n",
       "      <td>-122.42_37.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>GRAND THEFT FROM LOCKED AUTO</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1500 Block of LOMBARD ST</td>\n",
       "      <td>-122.426995</td>\n",
       "      <td>37.800873</td>\n",
       "      <td>-122.43_37.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>GRAND THEFT FROM LOCKED AUTO</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>PARK</td>\n",
       "      <td>NONE</td>\n",
       "      <td>100 Block of BRODERICK ST</td>\n",
       "      <td>-122.438738</td>\n",
       "      <td>37.771541</td>\n",
       "      <td>-122.44_37.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Dates        Category                      Descript  \\\n",
       "0 2015-05-13 23:53:00        WARRANTS                WARRANT ARREST   \n",
       "1 2015-05-13 23:53:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
       "2 2015-05-13 23:33:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
       "3 2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
       "4 2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
       "\n",
       "   DayOfWeek PdDistrict      Resolution                    Address  \\\n",
       "0  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
       "1  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
       "2  Wednesday   NORTHERN  ARREST, BOOKED  VANNESS AV / GREENWICH ST   \n",
       "3  Wednesday   NORTHERN            NONE   1500 Block of LOMBARD ST   \n",
       "4  Wednesday       PARK            NONE  100 Block of BRODERICK ST   \n",
       "\n",
       "            X          Y       location  \n",
       "0 -122.425892  37.774599  -122.43_37.77  \n",
       "1 -122.425892  37.774599  -122.43_37.77  \n",
       "2 -122.424363  37.800414   -122.42_37.8  \n",
       "3 -122.426995  37.800873   -122.43_37.8  \n",
       "4 -122.438738  37.771541  -122.44_37.77  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139, 140)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.location.nunique(), test.location.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's encode our location strings as integers. One complication is that there is a location in the test set that is not in the training set. So we cheat a bit and fit the encoder on the test locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "locEnc = sklearn.preprocessing.LabelEncoder()\n",
    "locEnc.fit(test.location.unique())\n",
    "test['location'] = locEnc.transform(test.location)\n",
    "train['location'] = locEnc.transform(train.location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50\n",
       "1    50\n",
       "2    42\n",
       "3    53\n",
       "4    61\n",
       "Name: location, dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.location.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll preprocess the other columns using the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "categoryEncoder = LabelEncoder() #save as variable so we can use later while creating submission\n",
    "\n",
    "\n",
    "def clean(df, isTrain=True):\n",
    "    ## we need to clean the train and tests sets somewhat differently, hence the isTrain argument above\n",
    "    \n",
    "    ## transform the variable we will predict into a numeric category so our model can handle it. \n",
    "    if (isTrain):\n",
    "        df['Category'] = categoryEncoder.fit(df.Category).transform(df.Category)\n",
    "    \n",
    "    ## parse the Date variable into component parts so that our model can take advantage of that information\n",
    "    df['month'] = df.Dates.dt.month\n",
    "    df['dayOfMonth'] = df.Dates.dt.day\n",
    "    df['year'] = df.Dates.dt.year\n",
    "    df['hour'] = df.Dates.dt.hour\n",
    "    \n",
    "    \n",
    "    #create dummy variables for our categorical variables \n",
    "    df = df.merge(pd.get_dummies(df, columns=['DayOfWeek', 'year', 'month', 'PdDistrict', 'dayOfMonth', 'hour']))\n",
    "    \n",
    "    dropForTrain = [\n",
    "                    'Descript', #Not in test, so not helpful for modeling\n",
    "                    'Dates',  #We've parsed it into components\n",
    "                    'Resolution', #Not in test, so not helpful for modeling\n",
    "                    'Address',  # Too many unique values to dummy encode\n",
    "                    'month', #Dummy Encoded Columns\n",
    "                    'dayOfMonth', \n",
    "                    'hour',\n",
    "                    'year',\n",
    "                    'DayOfWeek',\n",
    "                    'PdDistrict'\n",
    "                    ]\n",
    "    \n",
    "    dropForTest = [\n",
    "        'Dates', \n",
    "        'Address', \n",
    "        'year',\n",
    "        'DayOfWeek',\n",
    "        'month', \n",
    "        'dayOfMonth', \n",
    "        'hour',\n",
    "        'PdDistrict'\n",
    "    ]\n",
    "    \n",
    "    if (isTrain):\n",
    "        df = df.drop(dropForTrain, axis=1)\n",
    "    else:\n",
    "        df = df.drop(dropForTest, axis=1)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainClean = clean(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testClean = clean(test, isTrain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((883987, 101), (884262, 101))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainClean.shape, testClean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a logistic regression classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train our model. First, we'll split the data into our features and our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = trainClean.drop('Category', axis=1)\n",
    "y = trainClean.Category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll train a logistic regression classifier and tune 'C', its regularization parameter. We use multinomial logistic regression instead of one-vs-all because the Kaggle competition is judged on log loss. Mutinomial produces better calibrated probabilities than one-vs-all, and so should perform better in respect to log loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] C=0.001 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanryanadmin/anaconda3/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................... C=0.001, score=-2.672714 - 1.7min\n",
      "[CV] C=0.001 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.7min remaining:    0.0s\n",
      "/home/ryanryanadmin/anaconda3/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................... C=0.001, score=-2.665976 - 1.7min\n",
      "[CV] C=0.001 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  3.5min remaining:    0.0s\n",
      "/home/ryanryanadmin/anaconda3/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................... C=0.001, score=-2.665822 - 1.7min\n",
      "[CV] C=0.01 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  5.2min remaining:    0.0s\n",
      "/home/ryanryanadmin/anaconda3/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................ C=0.01, score=-2.672670 - 1.5min\n",
      "[CV] C=0.01 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  6.7min remaining:    0.0s\n",
      "/home/ryanryanadmin/anaconda3/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................ C=0.01, score=-2.665987 - 1.6min\n",
      "[CV] C=0.01 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanryanadmin/anaconda3/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................ C=0.01, score=-2.665749 - 1.6min\n",
      "[CV] C=0.1 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanryanadmin/anaconda3/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. C=0.1, score=-2.672710 - 1.6min\n",
      "[CV] C=0.1 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanryanadmin/anaconda3/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. C=0.1, score=-2.665988 - 1.5min\n",
      "[CV] C=0.1 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanryanadmin/anaconda3/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. C=0.1, score=-2.665749 - 1.5min\n",
      "[CV] C=1 .............................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanryanadmin/anaconda3/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................... C=1, score=-2.672717 - 1.5min\n",
      "[CV] C=1 .............................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanryanadmin/anaconda3/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................... C=1, score=-2.665988 - 1.5min\n",
      "[CV] C=1 .............................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanryanadmin/anaconda3/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................... C=1, score=-2.665749 - 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed: 19.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01}\n"
     ]
    }
   ],
   "source": [
    "softMax = LogisticRegression(multi_class='multinomial', solver='lbfgs', tol=1e-2, max_iter=50)\n",
    "softMaxParams = {'C': [1e-3, 1e-2, 1e-1, 1]}\n",
    "\n",
    "gs = GridSearchCV(estimator = softMax, param_grid=softMaxParams, verbose=5, scoring='log_loss') \n",
    "gs.fit(X, y)\n",
    "\n",
    "print(gs.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions and creating the submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our submission using the helper function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_cats = train.Category.nunique()\n",
    "def createSubmission(est, filePath):\n",
    "    \n",
    "    #get the category names for the header of the submission file.\n",
    "    catLabels = categoryEncoder.inverse_transform(np.arange(num_cats))\n",
    "\n",
    "    #because we've already selected our hyperparameters, we can now fit our estimator on the entire training set\n",
    "    est.fit(X, y)\n",
    "    \n",
    "    # get the probabilities that a crime belongs to each category.\n",
    "    testProbs = est.predict_proba(testClean.drop('Id', axis=1))\n",
    "    \n",
    "    #create our data frame and save it as a csv.\n",
    "    subDf = pd.DataFrame(testProbs, columns=catLabels)\n",
    "    subDf = pd.concat([testClean.Id, subDf], axis=1)\n",
    "    subDf.to_csv(filePath, index=False)\n",
    "    print('created {}'.format(filePath))\n",
    "    return subDf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now let's use our function to create our submission!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created my_submission_7.csv\n"
     ]
    }
   ],
   "source": [
    "sub = createSubmission(gs.best_estimator_, 'my_submission_7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ARSON</th>\n",
       "      <th>ASSAULT</th>\n",
       "      <th>BAD CHECKS</th>\n",
       "      <th>BRIBERY</th>\n",
       "      <th>BURGLARY</th>\n",
       "      <th>DISORDERLY CONDUCT</th>\n",
       "      <th>DRIVING UNDER THE INFLUENCE</th>\n",
       "      <th>DRUG/NARCOTIC</th>\n",
       "      <th>DRUNKENNESS</th>\n",
       "      <th>...</th>\n",
       "      <th>SEX OFFENSES NON FORCIBLE</th>\n",
       "      <th>STOLEN PROPERTY</th>\n",
       "      <th>SUICIDE</th>\n",
       "      <th>SUSPICIOUS OCC</th>\n",
       "      <th>TREA</th>\n",
       "      <th>TRESPASS</th>\n",
       "      <th>VANDALISM</th>\n",
       "      <th>VEHICLE THEFT</th>\n",
       "      <th>WARRANTS</th>\n",
       "      <th>WEAPON LAWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.074269</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.050240</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0.003807</td>\n",
       "      <td>0.021296</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.004628</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.041416</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.006741</td>\n",
       "      <td>0.061511</td>\n",
       "      <td>0.072948</td>\n",
       "      <td>0.031431</td>\n",
       "      <td>0.006096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001881</td>\n",
       "      <td>0.094255</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.035763</td>\n",
       "      <td>0.006491</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.099967</td>\n",
       "      <td>0.005205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.005026</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.030857</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.008974</td>\n",
       "      <td>0.043280</td>\n",
       "      <td>0.051815</td>\n",
       "      <td>0.059636</td>\n",
       "      <td>0.011861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.001832</td>\n",
       "      <td>0.088728</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.041816</td>\n",
       "      <td>0.005183</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>0.058244</td>\n",
       "      <td>0.005108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.005020</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.035398</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.008316</td>\n",
       "      <td>0.050734</td>\n",
       "      <td>0.060470</td>\n",
       "      <td>0.048505</td>\n",
       "      <td>0.009547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.001826</td>\n",
       "      <td>0.088292</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.042407</td>\n",
       "      <td>0.005057</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.054933</td>\n",
       "      <td>0.005094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.005015</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.035907</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.008241</td>\n",
       "      <td>0.051599</td>\n",
       "      <td>0.061636</td>\n",
       "      <td>0.047379</td>\n",
       "      <td>0.009329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.001826</td>\n",
       "      <td>0.088292</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.042407</td>\n",
       "      <td>0.005057</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.054933</td>\n",
       "      <td>0.005094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.005015</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.035907</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.008241</td>\n",
       "      <td>0.051599</td>\n",
       "      <td>0.061636</td>\n",
       "      <td>0.047379</td>\n",
       "      <td>0.009329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id     ARSON   ASSAULT  BAD CHECKS   BRIBERY  BURGLARY  DISORDERLY CONDUCT  \\\n",
       "0   0  0.001620  0.074269    0.000419  0.000151  0.050240            0.003258   \n",
       "1   1  0.001881  0.094255    0.000583  0.000382  0.035763            0.006491   \n",
       "2   2  0.001832  0.088728    0.000531  0.000279  0.041816            0.005183   \n",
       "3   3  0.001826  0.088292    0.000525  0.000270  0.042407            0.005057   \n",
       "4   4  0.001826  0.088292    0.000525  0.000270  0.042407            0.005057   \n",
       "\n",
       "   DRIVING UNDER THE INFLUENCE  DRUG/NARCOTIC  DRUNKENNESS     ...       \\\n",
       "0                     0.003807       0.021296     0.004571     ...        \n",
       "1                     0.001746       0.099967     0.005205     ...        \n",
       "2                     0.002396       0.058244     0.005108     ...        \n",
       "3                     0.002476       0.054933     0.005094     ...        \n",
       "4                     0.002476       0.054933     0.005094     ...        \n",
       "\n",
       "   SEX OFFENSES NON FORCIBLE  STOLEN PROPERTY   SUICIDE  SUSPICIOUS OCC  \\\n",
       "0                   0.000042         0.004628  0.000548        0.041416   \n",
       "1                   0.000140         0.005026  0.000732        0.030857   \n",
       "2                   0.000092         0.005020  0.000677        0.035398   \n",
       "3                   0.000088         0.005015  0.000671        0.035907   \n",
       "4                   0.000088         0.005015  0.000671        0.035907   \n",
       "\n",
       "       TREA  TRESPASS  VANDALISM  VEHICLE THEFT  WARRANTS  WEAPON LAWS  \n",
       "0  0.000006  0.006741   0.061511       0.072948  0.031431     0.006096  \n",
       "1  0.000036  0.008974   0.043280       0.051815  0.059636     0.011861  \n",
       "2  0.000020  0.008316   0.050734       0.060470  0.048505     0.009547  \n",
       "3  0.000018  0.008241   0.051599       0.061636  0.047379     0.009329  \n",
       "4  0.000018  0.008241   0.051599       0.061636  0.047379     0.009329  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
