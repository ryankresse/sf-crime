{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 12.0)\n",
    "matplotlib.rcParams['axes.titlesize'] = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/train.csv', parse_dates=['Dates'])\n",
    "test = pd.read_csv('input/test.csv', parse_dates=['Dates'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first see if there are missing values in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dates         0\n",
       "Category      0\n",
       "Descript      0\n",
       "DayOfWeek     0\n",
       "PdDistrict    0\n",
       "Resolution    0\n",
       "Address       0\n",
       "X             0\n",
       "Y             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id            0\n",
       "Dates         0\n",
       "DayOfWeek     0\n",
       "PdDistrict    0\n",
       "Address       0\n",
       "X             0\n",
       "Y             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice. So we have a completely full data set.\n",
    "\n",
    "Below is a function we'll use to prepare the data for training. I've commented the code as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "categoryEncoder = LabelEncoder()\n",
    "\n",
    "def clean(df, isTrain=True):\n",
    "    ## we need to clean the train and tests sets somewhat differently, hence the isTrain argument above\n",
    "    \n",
    "    ## transform the variable we will predict into a numeric category so our model can handle it. \n",
    "    if (isTrain):\n",
    "        df['Category'] = categoryEncoder.fit(df.Category).transform(df.Category)\n",
    "    \n",
    "    ## parse the Date variable into component parts so that our model can take advantage of that information\n",
    "    df['month'] = df.Dates.dt.month\n",
    "    df['dayOfMonth'] = df.Dates.dt.day\n",
    "    df['year'] = df.Dates.dt.year\n",
    "    df['hour'] = df.Dates.dt.hour\n",
    "    \n",
    "    #create dummy variables for our categorical variables \n",
    "    df = df.merge(pd.get_dummies(df, columns=['DayOfWeek', 'year', 'month', 'PdDistrict', 'dayOfMonth', 'hour']))\n",
    "    \n",
    "    dropForTrain = [\n",
    "                    'Descript', #Not in test, so not helpful for modeling\n",
    "                    'Dates',  #We've parsed it into components\n",
    "                    'Resolution', #Not in test, so not helpful for modeling\n",
    "                    'Address',  # Too many unique values to dummy encode\n",
    "                    'month', #Dummy Encoded Columns\n",
    "                    'dayOfMonth', \n",
    "                    'hour',\n",
    "                    'year',\n",
    "                    'DayOfWeek',\n",
    "                    'PdDistrict'\n",
    "                    ]\n",
    "    \n",
    "    dropForTest = [\n",
    "        'Dates', \n",
    "        'Address', \n",
    "        'year',\n",
    "        'DayOfWeek',\n",
    "        'month', \n",
    "        'dayOfMonth', \n",
    "        'hour',\n",
    "        'PdDistrict'\n",
    "    ]\n",
    "    \n",
    "    if (isTrain):\n",
    "        df = df.drop(dropForTrain, axis=1)\n",
    "    else:\n",
    "        df = df.drop(dropForTest, axis=1)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainClean = clean(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Category', 'X', 'Y', 'DayOfWeek_Friday', 'DayOfWeek_Monday',\n",
       "       'DayOfWeek_Saturday', 'DayOfWeek_Sunday', 'DayOfWeek_Thursday',\n",
       "       'DayOfWeek_Tuesday', 'DayOfWeek_Wednesday', 'year_2003', 'year_2004',\n",
       "       'year_2005', 'year_2006', 'year_2007', 'year_2008', 'year_2009',\n",
       "       'year_2010', 'year_2011', 'year_2012', 'year_2013', 'year_2014',\n",
       "       'year_2015', 'month_1', 'month_2', 'month_3', 'month_4', 'month_5',\n",
       "       'month_6', 'month_7', 'month_8', 'month_9', 'month_10', 'month_11',\n",
       "       'month_12', 'PdDistrict_BAYVIEW', 'PdDistrict_CENTRAL',\n",
       "       'PdDistrict_INGLESIDE', 'PdDistrict_MISSION', 'PdDistrict_NORTHERN',\n",
       "       'PdDistrict_PARK', 'PdDistrict_RICHMOND', 'PdDistrict_SOUTHERN',\n",
       "       'PdDistrict_TARAVAL', 'PdDistrict_TENDERLOIN', 'dayOfMonth_1',\n",
       "       'dayOfMonth_2', 'dayOfMonth_3', 'dayOfMonth_4', 'dayOfMonth_5',\n",
       "       'dayOfMonth_6', 'dayOfMonth_7', 'dayOfMonth_8', 'dayOfMonth_9',\n",
       "       'dayOfMonth_10', 'dayOfMonth_11', 'dayOfMonth_12', 'dayOfMonth_13',\n",
       "       'dayOfMonth_14', 'dayOfMonth_15', 'dayOfMonth_16', 'dayOfMonth_17',\n",
       "       'dayOfMonth_18', 'dayOfMonth_19', 'dayOfMonth_20', 'dayOfMonth_21',\n",
       "       'dayOfMonth_22', 'dayOfMonth_23', 'dayOfMonth_24', 'dayOfMonth_25',\n",
       "       'dayOfMonth_26', 'dayOfMonth_27', 'dayOfMonth_28', 'dayOfMonth_29',\n",
       "       'dayOfMonth_30', 'dayOfMonth_31', 'hour_0', 'hour_1', 'hour_2',\n",
       "       'hour_3', 'hour_4', 'hour_5', 'hour_6', 'hour_7', 'hour_8', 'hour_9',\n",
       "       'hour_10', 'hour_11', 'hour_12', 'hour_13', 'hour_14', 'hour_15',\n",
       "       'hour_16', 'hour_17', 'hour_18', 'hour_19', 'hour_20', 'hour_21',\n",
       "       'hour_22', 'hour_23'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainClean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testClean = clean(test, isTrain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>DayOfWeek_Friday</th>\n",
       "      <th>DayOfWeek_Monday</th>\n",
       "      <th>DayOfWeek_Saturday</th>\n",
       "      <th>DayOfWeek_Sunday</th>\n",
       "      <th>DayOfWeek_Thursday</th>\n",
       "      <th>DayOfWeek_Tuesday</th>\n",
       "      <th>DayOfWeek_Wednesday</th>\n",
       "      <th>...</th>\n",
       "      <th>hour_14</th>\n",
       "      <th>hour_15</th>\n",
       "      <th>hour_16</th>\n",
       "      <th>hour_17</th>\n",
       "      <th>hour_18</th>\n",
       "      <th>hour_19</th>\n",
       "      <th>hour_20</th>\n",
       "      <th>hour_21</th>\n",
       "      <th>hour_22</th>\n",
       "      <th>hour_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-122.399588</td>\n",
       "      <td>37.735051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-122.391523</td>\n",
       "      <td>37.732432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-122.426002</td>\n",
       "      <td>37.792212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-122.437394</td>\n",
       "      <td>37.721412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-122.437394</td>\n",
       "      <td>37.721412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id           X          Y  DayOfWeek_Friday  DayOfWeek_Monday  \\\n",
       "0   0 -122.399588  37.735051               0.0               0.0   \n",
       "1   1 -122.391523  37.732432               0.0               0.0   \n",
       "2   2 -122.426002  37.792212               0.0               0.0   \n",
       "3   3 -122.437394  37.721412               0.0               0.0   \n",
       "4   4 -122.437394  37.721412               0.0               0.0   \n",
       "\n",
       "   DayOfWeek_Saturday  DayOfWeek_Sunday  DayOfWeek_Thursday  \\\n",
       "0                 0.0               1.0                 0.0   \n",
       "1                 0.0               1.0                 0.0   \n",
       "2                 0.0               1.0                 0.0   \n",
       "3                 0.0               1.0                 0.0   \n",
       "4                 0.0               1.0                 0.0   \n",
       "\n",
       "   DayOfWeek_Tuesday  DayOfWeek_Wednesday   ...     hour_14  hour_15  hour_16  \\\n",
       "0                0.0                  0.0   ...         0.0      0.0      0.0   \n",
       "1                0.0                  0.0   ...         0.0      0.0      0.0   \n",
       "2                0.0                  0.0   ...         0.0      0.0      0.0   \n",
       "3                0.0                  0.0   ...         0.0      0.0      0.0   \n",
       "4                0.0                  0.0   ...         0.0      0.0      0.0   \n",
       "\n",
       "   hour_17  hour_18  hour_19  hour_20  hour_21  hour_22  hour_23  \n",
       "0      0.0      0.0      0.0      0.0      0.0      0.0      1.0  \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0      1.0  \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0      1.0  \n",
       "3      0.0      0.0      0.0      0.0      0.0      0.0      1.0  \n",
       "4      0.0      0.0      0.0      0.0      0.0      0.0      1.0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testClean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'X', 'Y', 'DayOfWeek_Friday', 'DayOfWeek_Monday',\n",
       "       'DayOfWeek_Saturday', 'DayOfWeek_Sunday', 'DayOfWeek_Thursday',\n",
       "       'DayOfWeek_Tuesday', 'DayOfWeek_Wednesday', 'year_2003', 'year_2004',\n",
       "       'year_2005', 'year_2006', 'year_2007', 'year_2008', 'year_2009',\n",
       "       'year_2010', 'year_2011', 'year_2012', 'year_2013', 'year_2014',\n",
       "       'year_2015', 'month_1', 'month_2', 'month_3', 'month_4', 'month_5',\n",
       "       'month_6', 'month_7', 'month_8', 'month_9', 'month_10', 'month_11',\n",
       "       'month_12', 'PdDistrict_BAYVIEW', 'PdDistrict_CENTRAL',\n",
       "       'PdDistrict_INGLESIDE', 'PdDistrict_MISSION', 'PdDistrict_NORTHERN',\n",
       "       'PdDistrict_PARK', 'PdDistrict_RICHMOND', 'PdDistrict_SOUTHERN',\n",
       "       'PdDistrict_TARAVAL', 'PdDistrict_TENDERLOIN', 'dayOfMonth_1',\n",
       "       'dayOfMonth_2', 'dayOfMonth_3', 'dayOfMonth_4', 'dayOfMonth_5',\n",
       "       'dayOfMonth_6', 'dayOfMonth_7', 'dayOfMonth_8', 'dayOfMonth_9',\n",
       "       'dayOfMonth_10', 'dayOfMonth_11', 'dayOfMonth_12', 'dayOfMonth_13',\n",
       "       'dayOfMonth_14', 'dayOfMonth_15', 'dayOfMonth_16', 'dayOfMonth_17',\n",
       "       'dayOfMonth_18', 'dayOfMonth_19', 'dayOfMonth_20', 'dayOfMonth_21',\n",
       "       'dayOfMonth_22', 'dayOfMonth_23', 'dayOfMonth_24', 'dayOfMonth_25',\n",
       "       'dayOfMonth_26', 'dayOfMonth_27', 'dayOfMonth_28', 'dayOfMonth_29',\n",
       "       'dayOfMonth_30', 'dayOfMonth_31', 'hour_0', 'hour_1', 'hour_2',\n",
       "       'hour_3', 'hour_4', 'hour_5', 'hour_6', 'hour_7', 'hour_8', 'hour_9',\n",
       "       'hour_10', 'hour_11', 'hour_12', 'hour_13', 'hour_14', 'hour_15',\n",
       "       'hour_16', 'hour_17', 'hour_18', 'hour_19', 'hour_20', 'hour_21',\n",
       "       'hour_22', 'hour_23'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testClean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a logistic regression classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's split the data into our features and our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold \n",
    "X = trainClean.drop('Category', axis=1)\n",
    "y = trainClean.Category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll train a logistic regression classifier and tune 'C', its regularization parameter. We use multinomial logistic regression instead of one-vs-all because the Kaggle competition is judged on log loss. Mutinomial produces better calibrated probabilities than one-vs-all, and so should perform better in respect to log loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ................................. C=0.1, score=-2.681987 - 5.4min\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ................................. C=0.1, score=-2.682590 - 4.9min\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ................................. C=0.1, score=-2.679856 - 5.1min\n",
      "[CV] C=1 .............................................................\n",
      "[CV] ................................... C=1, score=-2.681988 - 5.0min\n",
      "[CV] C=1 .............................................................\n",
      "[CV] ................................... C=1, score=-2.682591 - 4.9min\n",
      "[CV] C=1 .............................................................\n",
      "[CV] ................................... C=1, score=-2.679856 - 4.9min\n",
      "[CV] C=10 ............................................................\n",
      "[CV] .................................. C=10, score=-2.681988 - 5.3min\n",
      "[CV] C=10 ............................................................\n",
      "[CV] .................................. C=10, score=-2.682591 - 5.3min\n",
      "[CV] C=10 ............................................................\n",
      "[CV] .................................. C=10, score=-2.679856 - 5.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 46.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "softMax = LogisticRegression(multi_class='multinomial', solver='lbfgs', tol=1e-2, max_iter=50)\n",
    "softMaxParams = {'C': [1e-1, 1, 10]}\n",
    "\n",
    "gs = GridSearchCV(estimator = softMax, param_grid=softMaxParams, verbose=5, scoring='log_loss') \n",
    "gs.fit(X, y)\n",
    "\n",
    "print(gs.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions and creating the submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a helper function to create a submission for any estimator that has a predict_proba method.\n",
    "\n",
    "The trickiest part is formatting the submission. We need to use the category names as the column names, but the categories of our clean training set have already been converted to numbers. To get the names back, we read in the original names from the raw train.csv file, fit a label encoder to those names, then use that encoder transform the numeric representations in our clean training set back into their corresponding names. Essentially, we're just undoing what we did when we cleaned the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "trainCats = pd.read_csv('input/train.csv', usecols=['Category'])\n",
    "\n",
    "def createSubmission(est, filePath):\n",
    "    \n",
    "    #because we've already selected our hyperparameters, we can now fit our estimator on the entire training set\n",
    "    est.fit(X, y)\n",
    "    \n",
    "    # get the probabilities that a crime belongs to each category.\n",
    "    testProbs = est.predict_proba(testClean.drop('Id', axis=1))\n",
    "    \n",
    "    #get the category names for the header of the submission file.\n",
    "    categoryEncoder = LabelEncoder()\n",
    "    categoryEncoder.fit(trainCats.Category)\n",
    "    catLabels = categoryEncoder.inverse_transform(trainClean.Category.unique())\n",
    "    \n",
    "    subDf = pd.DataFrame(testProbs, columns=catLabels)\n",
    "    subDf = pd.concat([testClean.Id, subDf], axis=1)\n",
    "    subDf.to_csv(filePath, index=False)\n",
    "    print('created {}'.format(filePath))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now let's use our function to create our submission!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created my_submission.csv\n"
     ]
    }
   ],
   "source": [
    "createSubmission(gs.best_estimator_, 'my_submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
